{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Version control and collaboration with Git and Github\n",
    "# 52 pts, Due Thursday May 20 at 11:59pm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Helpful Resources:**# \n",
    "\n",
    "- [Getting help on a Jupyter Notebook](https://problemsolvingwithpython.com/02-Jupyter-Notebooks/02.07-Getting-Help-in-a-Jupyter-Notebook/)\n",
    "\n",
    "- [Python Examples](https://nbviewer.jupyter.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/Python_101.ipynb): A reference for distinct Python commands (worth returning to throughout this course)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *This week's* homework groups. \n",
    "\n",
    "Homework groups this week are:\n",
    "```\n",
    "[Riely Anton Michael] [Kei Alex] [Sophie Skyler]\n",
    "```\n",
    "\n",
    "You will need to work collaboratively with your group for Question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 1: Plotting Mauna Loa data via a git repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!matplotlib inline\n",
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ml)\n",
    "filename='mauna_loa2.csv'\n",
    "import ml\n",
    "df=ml.get_df(filename)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Working collaboratively with Git and Github (30 pts)\n",
    "In this exercise, you will work collaboratively to write analysis and plotting routines that use data from the New York Times Covid-19 data repository.\n",
    "The final goal is to make three plots akin to  this one.<br>\n",
    "<img src='states.svg' width=\"500px\" /><br>\n",
    "To do this, I would like you to collaboratively write the four functions defined in covid_plot.py.\n",
    "One member of your group should start by creating a new repository titled covid_plotting on GitHub and inviting the other members of the group as collaborators. Then you should decide how you want to divide the work and push and pull commits as you go from your local git repositories on the class server. **NOTE:** Make your local git repository for this project distinct from this homework directory as you do not want to include this Jupyter notebook in repository.\n",
    "Note that your Python coding will be on the covid_plot.py file. Also note that the make_plot function depends on the ability to read_in_data but not on get_extreme_states, so that work can be done in parallel. You should be able to work simultaneously and resolve any conflicts. \n",
    "I would like each member of the group to make some contribution to each function, even if it's inserting a comment. \n",
    "The final repository should also contain a Jupyter notebook which makes three plots.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'covid_plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-05b2bc706e5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Code that should make plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcovid_plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcovid_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_in_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlow_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhigh_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcovid_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extreme_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Oregon'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'California'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Texas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'covid_plot'"
     ]
    }
   ],
   "source": [
    "#Code that should make plot\n",
    "import covid_plot\n",
    "df=covid_plot.read_in_data(filename)\n",
    "low_states,high_states=covid_plot.get_extreme_states(df)\n",
    "states=['Oregon','California','Texas']\n",
    "ax,cr_state=covid_plot.make_plot(df,states)\n",
    "covid_plot.modify_plot(ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Old Faithful Redux\n",
    "The [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) is defined as the covariance of two variables divided by their standard deviation. The possible values of the correlation coefficient vary between -1 (absolute negative correlation) and 1 (absolute positive correlation).\n",
    "In HW 2, to develop our skills with Pandas, we examined a classic data set from observations of the Old Faithful geyser, recording a series of paired eruption durations and waiting times until the next eruption. Here, we re-examine this data set to infer general properties of the geyser from the limited sample. <br>\n",
    "To get started, load in the data from `old_faithful.csv` and remake the scatter plot from HW 2, Question 1f. These data are suggestive of a correlation between eruption duration and waiting time.  <br>\n",
    "**Question 2a:** Using the `np.corrcoef` method, calculate the observed correlation coefficient for these paired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ellipsis\n"
     ]
    }
   ],
   "source": [
    "#Answer 2a: Make plot and calculate correlation coefficient\n",
    "\n",
    "\n",
    "\n",
    "correlation_coefficient=...\n",
    "print(correlation_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2b:** Is this correlation coefficient greater than would be expected if we randomly shuffled the observed pairings? Permute the data 1,000 times and make a plot of the distribution of correlation coefficients that would be expected by chance. Plot the observed correlation coefficient as a vertical line. What is the proportion of this simulated distribution which has a correlation coefficient greater than to the observed value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of simulated distribution with correlation coefficient higher than observed is Ellipsis\n"
     ]
    }
   ],
   "source": [
    "#Answer 2b\n",
    "#Make a plot\n",
    "\n",
    "\n",
    "pvalue=...\n",
    "print('The proportion of simulated distribution with correlation coefficient higher than observed is', pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2c:**\n",
    "An alternative approach to evaluating the significance of a correlation coefficient is to create a 95% confidence interval. To do this, you can perform a bootstrap, repeatedly resampling the observed data with replacement. Using 1,000 bootstraps, determine the 95% confidence interval for the correlation coefficient based on the observed sample. Plot the distribution of expected correlation coefficients as a histogram and the 95% confidence interval as a horizontal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ellipsis\n",
      "Ellipsis\n"
     ]
    }
   ],
   "source": [
    "#Answer 2c\n",
    "#Make plot and save bounds of confidence interval below\n",
    "\n",
    "lower_bound= ...\n",
    "print(lower_bound)\n",
    "higher_bound= ...\n",
    "print(higher_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2d:** The bootstrap can be used to estimate the underlying expected distribution of any statistical parameter. Use a bootstrap approach (1,000 samples) to estimate the probability that an eruption will last longer than 3 minutes. The observed probability, in the original sample, is the proportion of the eruptions longer than 3 minutes. Create a histogram of bootstrap replicates, evaluating the probabilities expected with repeated sampling. Calculate a 95% confidence interval and save it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ellipsis\n",
      "Ellipsis\n"
     ]
    }
   ],
   "source": [
    "#Answer 2d\n",
    "#Make plot and save bounds of confidence interval below\n",
    "\n",
    "lower_bound= ...\n",
    "print(lower_bound)\n",
    "higher_bound= ...\n",
    "print(higher_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus question: How do changes in sample size affect the significance of the Pearson correlation coefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good question came up in lecture: *Does the value of the correlation coefficient, in itself, convey information about statistical significance?*\n",
    "I encourage you to try to address that question by evaluating the significance of datasets that have matched correlation coefficients but different amounts of data.\n",
    "\n",
    "The cell below creates a Python dictionary `paired_data` which has three sets of (x,y) paired arrays of different length. In each case, data arrays are constructed so that correlation coefficient is ~ 0.2\n",
    "\n",
    "`paired_data['20']` contains 20 x,y pairs<br>\n",
    "`paired_data['500']` contains 500 x,y pairs<br> \n",
    "`paired_data['5000']` contains 5000 x,y pairs.\n",
    "\n",
    "For each of these three paired arrays, compute the significance of the correlation using a permutation-based approach. What do the results suggest about how the value of significance changes when correlation coefficient remains constant but the amount of data increases?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates dictionary paired_data\n",
    "#paired_data keys are '20', '500', '5000' corresponding to number of x,y pairs\n",
    "#paired_data['20'] is a 2x20 array with 20 x,y pairs. \n",
    "\n",
    "\n",
    "correlation_level=0.2\n",
    "import numpy as np\n",
    "paired_data={}\n",
    "all_nvals=[20,500,5000]\n",
    "\n",
    "for cr_nvals in all_nvals:\n",
    "    xvals= np.array([-1, 1])\n",
    "    yvals = np.array([-1, 1])\n",
    "    means = [xvals.mean(), yvals.mean()]  \n",
    "    stds = [xvals.std() / 3, yvals.std() / 3]\n",
    "    corr = correlation_level       # correlation\n",
    "    covs = [[stds[0]**2          , stds[0]*stds[1]*corr], \n",
    "            [stds[0]*stds[1]*corr,           stds[1]**2]] \n",
    "\n",
    "    paired_data[str(cr_nvals)] = np.random.multivariate_normal(means, covs, cr_nvals).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bonus answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
